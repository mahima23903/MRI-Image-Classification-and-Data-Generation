# -*- coding: utf-8 -*-
"""classification task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dKL0vuYm3q83k7L8dnmi7Dakp_jRBDoJ
"""

'''!pip install keras==2.2.4
!pip install keras-nightly
!pip install keras-Preprocessing
!pip install keras-applications
!pip install mrcnn
!pip install tensorflow'''

# Uninstall potentially conflicting libraries
!pip uninstall keras keras-nightly keras-Preprocessing keras-applications mrcnn tensorflow

# Reinstall TensorFlow (without specifying a version, to get the latest compatible version)
!pip install tensorflow

# Install a compatible version of Keras (check TensorFlow documentation for compatibility)
!pip install keras

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/Brain tumor detection/archive (7).zip"

# Setting standard image size
img_size = (256,256)
batch_size = 32

# Dataset paths
train_dir = "/content/Training"
val_dir = "/content/Testing"

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1.0/255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

def build_cnn():
  model_cnn = Sequential([
      keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),
      keras.layers.BatchNormalization(),
      keras.layers.MaxPooling2D((2, 2)),

      keras.layers.Conv2D(64, (3, 3), activation='relu'),
      keras.layers.BatchNormalization(),
      keras.layers.MaxPooling2D((2, 2)),

      keras.layers.Conv2D(128, (3, 3), activation='relu'),
      keras.layers.BatchNormalization(),
      keras.layers.MaxPooling2D((2, 2)),
      keras.layers.Conv2D(128, (3, 3), activation='relu'),
      keras.layers.BatchNormalization(),
      keras.layers.MaxPooling2D((2, 2)),
      keras.layers.Dropout(0.5),
      keras.layers.Flatten(),
      keras.layers.Dense(128, activation='relu'),
      keras.layers.Dense(4, activation='softmax')
  ])
  return model_cnn

def build_resnet50():
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))
    base_model.trainable = True
    model = Sequential([
        base_model,
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
    ])
    return model

model = build_cnn()

model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

epochs = 15
history = model.fit(train_generator, validation_data=val_generator, epochs=epochs)

# Evaluate the model
val_loss, val_acc = model.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc * 100:.2f}%")

# Plot training history
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Classification Report
val_labels = np.concatenate([val_generator.classes])
predictions = np.argmax(model.predict(val_generator), axis=1)
print(classification_report(val_labels, predictions))
print(confusion_matrix(val_labels, predictions))

model_ = build_resnet50()

model_.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

epochs = 11
history = model_.fit(train_generator, validation_data=val_generator, epochs=epochs)

# Evaluate the model
val_loss, val_acc = model_.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc * 100:.2f}%")

# Plot training history
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def build_vgg16():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))
    base_model.trainable = False
    model = Sequential([
        base_model,
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
    ])
    return model

model_vgg = build_vgg16()

model_vgg.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

epochs = 15
history = model_vgg.fit(train_generator, validation_data=val_generator, epochs=epochs)

# Evaluate the model
val_loss, val_acc = model_vgg.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc * 100:.2f}%")

# Plot training history
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from tensorflow.keras.preprocessing import image

image_paths = ['/content/Testing/glioma/Te-glTr_0003.jpg','/content/Testing/meningioma/Te-meTr_0003.jpg','/content/Testing/notumor/Te-no_0162.jpg', '/content/Training/pituitary/Tr-pi_0042.jpg']

  # Iterate over the image paths
for img_path in image_paths:
      # Load and preprocess the image
      img = image.load_img(img_path, target_size=(256, 256))
      img_array = image.img_to_array(img)
      img_array = np.expand_dims(img_array, axis=0)
      preprocessed_img = img_array / 255.0  # Normalize the image

      class_labels = [ 'Glioma', 'Meningioma', 'Pituitary', 'No Tumor']  # Adjust based on dataset

      # Perform prediction
      prediction = model_.predict(preprocessed_img)
      print('Image:', img_path)
      print('Prediction:', prediction[0])

      # Get the predicted class index
      predicted_class_index = np.argmax(prediction)  # Finds the index of the highest probability

      # Get the class name
      predicted_class = class_labels[predicted_class_index]
# Display results
      print('Image:', img_path)
      print('Predicted Class:', predicted_class)
      print('Confidence Score:', np.max(prediction))

      # Plot the image
      import matplotlib.pyplot as plt
      plt.imshow(img)
      plt.show()
      print('\n')